{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of HLA-I peptides presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_file = r'X:\\Feng\\speclib_for_people\\MariaW\\IEDB_HLA_seqs\\IEDB_HLA1_seqs.tsv'\n",
    "save_as = r'X:\\Feng\\speclib_for_people\\MariaW\\HLA1_models\\HLA1_IEDB.pt'\n",
    "fasta = r'X:\\Feng\\speclib_for_people\\MariaW\\IEDB_HLA_seqs\\UP000005640_human_reviewed.fasta'\n",
    "pretrained_model = None\n",
    "\n",
    "### transfer learning\n",
    "# from peptdeep_hla.HLA_class_I import pretrained_HLA1\n",
    "# pretrained_model = pretrained_HLA1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For transfer learning of sample-specific models, please set pretrained_model as an existing model file and use sample-specific sequences instead of seq_file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>nAA</th>\n",
       "      <th>HLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAA</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAPYAGW</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAARAAAL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAATCALV</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAKAAAAV</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705738</th>\n",
       "      <td>VVVSIDRFLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705739</th>\n",
       "      <td>VYNMVVKL</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705740</th>\n",
       "      <td>WGKSKEWGRNCKGCN</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705741</th>\n",
       "      <td>YASLRSLV</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705742</th>\n",
       "      <td>YGDSKPQKF</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>705743 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sequence  nAA  HLA\n",
       "0         AAAAAAAAAAAAA   13    1\n",
       "1             AAAAPYAGW    9    1\n",
       "2             AAAARAAAL    9    1\n",
       "3             AAAATCALV    9    1\n",
       "4             AAAKAAAAV    9    1\n",
       "...                 ...  ...  ...\n",
       "705738       VVVSIDRFLR   10    1\n",
       "705739        VYNMVVKL     9    1\n",
       "705740  WGKSKEWGRNCKGCN   15    1\n",
       "705741         YASLRSLV    8    1\n",
       "705742        YGDSKPQKF    9    1\n",
       "\n",
       "[705743 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pep_df = pd.read_csv(seq_file)\n",
    "pep_df['nAA'] = pep_df.sequence.str.len()\n",
    "pep_df['HLA'] = 1\n",
    "pep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_two_dfs(df, ratio=0.8):\n",
    "    train_df = df.sample(frac=ratio, replace=False)\n",
    "    test_df = df.drop(train_df.index)\n",
    "    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
    "\n",
    "pos_train_df, pos_test_df = split_to_two_dfs(pep_df, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peptdeep_hla.utils import get_random_sequences\n",
    "\n",
    "def concat_neg_df(pos_df, prot_df):\n",
    "    df_list = [pos_df]\n",
    "    for nAA, group_df in pos_df.groupby('nAA'):\n",
    "        rnd_seqs = get_random_sequences(\n",
    "            prot_df, \n",
    "            n=len(group_df),\n",
    "            pep_len = nAA\n",
    "        )\n",
    "        df_list.append(pd.DataFrame(\n",
    "            dict(sequence=rnd_seqs,nAA=nAA,HLA=0)\n",
    "        ))\n",
    "    return pd.concat(df_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peptdeep_hla.HLA_class_I import HLA_Class_I_Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1669697"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HLA_Class_I_Classifier(\n",
    "    fasta_files=[fasta]\n",
    ")\n",
    "if pretrained_model:\n",
    "    model.load(pretrained_model)\n",
    "model.get_parameter_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] Epoch=1, lr=5e-06, loss=0.6934202649683322\n",
      "[Training] Epoch=2, lr=1e-05, loss=0.6809309575917586\n",
      "[Training] Epoch=3, lr=1.5e-05, loss=0.5204161433116445\n",
      "[Training] Epoch=4, lr=2e-05, loss=0.47359454867974765\n",
      "[Training] Epoch=5, lr=2.5e-05, loss=0.4567883534813827\n",
      "[Training] Epoch=6, lr=3e-05, loss=0.44786587419374935\n",
      "[Training] Epoch=7, lr=3.5e-05, loss=0.44158721043253846\n",
      "[Training] Epoch=8, lr=4e-05, loss=0.43846351127579525\n",
      "[Training] Epoch=9, lr=4.5e-05, loss=0.4339803845252631\n",
      "[Training] Epoch=10, lr=5e-05, loss=0.43052031791435097\n",
      "[Training] Epoch=11, lr=5.500000000000001e-05, loss=0.4305336721100897\n",
      "[Training] Epoch=12, lr=6e-05, loss=0.4276179648795218\n",
      "[Training] Epoch=13, lr=6.500000000000001e-05, loss=0.42716886929745945\n",
      "[Training] Epoch=14, lr=7e-05, loss=0.4234656994072896\n",
      "[Training] Epoch=15, lr=7.500000000000001e-05, loss=0.4201591965724837\n",
      "[Training] Epoch=16, lr=8e-05, loss=0.419028694618423\n",
      "[Training] Epoch=17, lr=8.5e-05, loss=0.41433650080887774\n",
      "[Training] Epoch=18, lr=9e-05, loss=0.40964173528383363\n",
      "[Training] Epoch=19, lr=9.5e-05, loss=0.40716676875105445\n",
      "[Training] Epoch=20, lr=0.0001, loss=0.4060081419517409\n",
      "[Training] Epoch=21, lr=9.996145181203615e-05, loss=0.4034504321948537\n",
      "[Training] Epoch=22, lr=9.98458666866564e-05, loss=0.40315041283391556\n",
      "[Training] Epoch=23, lr=9.965342284774632e-05, loss=0.399796617705867\n",
      "[Training] Epoch=24, lr=9.938441702975689e-05, loss=0.39947747779342363\n",
      "[Training] Epoch=25, lr=9.903926402016153e-05, loss=0.39785832892049033\n",
      "[Training] Epoch=26, lr=9.861849601988383e-05, loss=0.3961575797143972\n",
      "[Training] Epoch=27, lr=9.812276182268236e-05, loss=0.3948176346297534\n",
      "[Training] Epoch=28, lr=9.755282581475769e-05, loss=0.3931845472106394\n",
      "[Training] Epoch=29, lr=9.690956679612421e-05, loss=0.3921109066819245\n",
      "[Training] Epoch=30, lr=9.619397662556435e-05, loss=0.3919488346239306\n",
      "[Training] Epoch=31, lr=9.540715869125407e-05, loss=0.389337003118587\n",
      "[Training] Epoch=32, lr=9.45503262094184e-05, loss=0.3898963233772314\n",
      "[Training] Epoch=33, lr=9.362480035363986e-05, loss=0.38770953146916515\n",
      "[Training] Epoch=34, lr=9.263200821770461e-05, loss=0.3865325945165922\n",
      "[Training] Epoch=35, lr=9.157348061512727e-05, loss=0.38783201181663657\n",
      "[Training] Epoch=36, lr=9.045084971874738e-05, loss=0.38641432439381224\n",
      "[Training] Epoch=37, lr=8.926584654403724e-05, loss=0.38428433498121656\n",
      "[Training] Epoch=38, lr=8.802029828000156e-05, loss=0.3835674156557839\n",
      "[Training] Epoch=39, lr=8.671612547178428e-05, loss=0.38339631298802934\n",
      "[Training] Epoch=40, lr=8.535533905932738e-05, loss=0.38329015497891405\n",
      "[Training] Epoch=41, lr=8.39400372766471e-05, loss=0.38072642908906035\n",
      "[Training] Epoch=42, lr=8.247240241650918e-05, loss=0.38081579900012824\n",
      "[Training] Epoch=43, lr=8.095469746549172e-05, loss=0.37916160951245503\n",
      "[Training] Epoch=44, lr=7.938926261462366e-05, loss=0.3788730040473758\n",
      "[Training] Epoch=45, lr=7.777851165098012e-05, loss=0.3778981718814598\n",
      "[Training] Epoch=46, lr=7.612492823579745e-05, loss=0.376925989985466\n",
      "[Training] Epoch=47, lr=7.443106207484776e-05, loss=0.3762571560886671\n",
      "[Training] Epoch=48, lr=7.269952498697734e-05, loss=0.37596710504225966\n",
      "[Training] Epoch=49, lr=7.09329868768714e-05, loss=0.3754894990966005\n",
      "[Training] Epoch=50, lr=6.91341716182545e-05, loss=0.37442892452455917\n",
      "[Training] Epoch=51, lr=6.730585285387465e-05, loss=0.37413848391119037\n",
      "[Training] Epoch=52, lr=6.545084971874738e-05, loss=0.3736443042755127\n",
      "[Training] Epoch=53, lr=6.357202249325371e-05, loss=0.3722852040011928\n",
      "[Training] Epoch=54, lr=6.167226819279528e-05, loss=0.371701265955871\n",
      "[Training] Epoch=55, lr=5.9754516100806423e-05, loss=0.3701905570502551\n",
      "[Training] Epoch=56, lr=5.782172325201155e-05, loss=0.37065346285981954\n",
      "[Training] Epoch=57, lr=5.587686987289189e-05, loss=0.36999421395220844\n",
      "[Training] Epoch=58, lr=5.392295478639225e-05, loss=0.3692839596069084\n",
      "[Training] Epoch=59, lr=5.196299078795344e-05, loss=0.36840763873649096\n",
      "[Training] Epoch=60, lr=5e-05, loss=0.36838374098516863\n",
      "[Training] Epoch=61, lr=4.8037009212046586e-05, loss=0.3682059934116759\n",
      "[Training] Epoch=62, lr=4.607704521360776e-05, loss=0.36742386339970357\n",
      "[Training] Epoch=63, lr=4.412313012710813e-05, loss=0.3660555686028499\n",
      "[Training] Epoch=64, lr=4.2178276747988446e-05, loss=0.3658551145836992\n",
      "[Training] Epoch=65, lr=4.0245483899193595e-05, loss=0.366240849135057\n",
      "[Training] Epoch=66, lr=3.832773180720475e-05, loss=0.36404011508203904\n",
      "[Training] Epoch=67, lr=3.642797750674629e-05, loss=0.364656449151489\n",
      "[Training] Epoch=68, lr=3.4549150281252636e-05, loss=0.3634523689184549\n",
      "[Training] Epoch=69, lr=3.2694147146125345e-05, loss=0.3634392245760504\n",
      "[Training] Epoch=70, lr=3.086582838174551e-05, loss=0.363314218791026\n",
      "[Training] Epoch=71, lr=2.9067013123128613e-05, loss=0.3631577901120456\n",
      "[Training] Epoch=72, lr=2.7300475013022663e-05, loss=0.36219736056507756\n",
      "[Training] Epoch=73, lr=2.556893792515227e-05, loss=0.36194177691666585\n",
      "[Training] Epoch=74, lr=2.3875071764202563e-05, loss=0.36129718361035834\n",
      "[Training] Epoch=75, lr=2.2221488349019903e-05, loss=0.36132895985864244\n",
      "[Training] Epoch=76, lr=2.061073738537635e-05, loss=0.3603175113223634\n",
      "[Training] Epoch=77, lr=1.9045302534508297e-05, loss=0.3611343870747764\n",
      "[Training] Epoch=78, lr=1.7527597583490822e-05, loss=0.3600363230930184\n",
      "[Training] Epoch=79, lr=1.6059962723352904e-05, loss=0.36041713688733445\n",
      "[Training] Epoch=80, lr=1.4644660940672627e-05, loss=0.3590944606178212\n",
      "[Training] Epoch=81, lr=1.3283874528215733e-05, loss=0.35973207860622763\n",
      "[Training] Epoch=82, lr=1.1979701719998453e-05, loss=0.3595144451789136\n",
      "[Training] Epoch=83, lr=1.0734153455962765e-05, loss=0.35897142954592437\n",
      "[Training] Epoch=84, lr=9.549150281252633e-06, loss=0.3592670214063716\n",
      "[Training] Epoch=85, lr=8.426519384872733e-06, loss=0.35846018290744636\n",
      "[Training] Epoch=86, lr=7.367991782295391e-06, loss=0.35932096220412346\n",
      "[Training] Epoch=87, lr=6.375199646360142e-06, loss=0.3593388409547086\n",
      "[Training] Epoch=88, lr=5.449673790581611e-06, loss=0.35817553412239506\n",
      "[Training] Epoch=89, lr=4.592841308745932e-06, loss=0.35986381583618665\n",
      "[Training] Epoch=90, lr=3.8060233744356633e-06, loss=0.35900580433179746\n",
      "[Training] Epoch=91, lr=3.0904332038757977e-06, loss=0.35877996177043553\n",
      "[Training] Epoch=92, lr=2.4471741852423237e-06, loss=0.35855516274020355\n",
      "[Training] Epoch=93, lr=1.8772381773176417e-06, loss=0.358435768113946\n",
      "[Training] Epoch=94, lr=1.3815039801161721e-06, loss=0.35977374832585174\n",
      "[Training] Epoch=95, lr=9.607359798384785e-07, loss=0.35953398841731954\n",
      "[Training] Epoch=96, lr=6.15582970243117e-07, loss=0.35969835992129345\n",
      "[Training] Epoch=97, lr=3.465771522536854e-07, loss=0.3595471476046544\n",
      "[Training] Epoch=98, lr=1.5413331334360182e-07, loss=0.3593809838564891\n",
      "[Training] Epoch=99, lr=3.8548187963854956e-08, loss=0.3601249653213429\n",
      "[Training] Epoch=100, lr=0.0, loss=0.3597618320640528\n"
     ]
    }
   ],
   "source": [
    "model.train(pos_train_df, epoch=100, warmup_epoch=20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>nAA</th>\n",
       "      <th>HLA</th>\n",
       "      <th>HLA_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAA</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AADKAAAAY</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AADLTQIFEV</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAEPAALAY</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAKAKAAL</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282293</th>\n",
       "      <td>YAMENHSLREENRRLRLLEPVKRAQEMDAQTIAKLEKAFSEISGM</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.940797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282294</th>\n",
       "      <td>LVPSPSLPRGCWQPPGSKSRPHRQGAQGHRAQVTQPSPKEPDRIK</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.828227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282295</th>\n",
       "      <td>YRVYPEGTLELRRVTAEEAGLYTCVAQNLVGADTKTVSVVVGRALL</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.981596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282296</th>\n",
       "      <td>LSLGQQLLRATADEDLQTAILLLAHGSREEVNETCGEGDGCTALHLA</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282297</th>\n",
       "      <td>RDIGRVIKKSLVEATGVPGQHILVAVLPGLPTTAELFVLPYQDPAG...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282298 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sequence  nAA  HLA  \\\n",
       "0                                           AAAAAAAAAAAAA   13    1   \n",
       "1                                               AADKAAAAY    9    1   \n",
       "2                                              AADLTQIFEV   10    1   \n",
       "3                                               AAEPAALAY    9    1   \n",
       "4                                                AAKAKAAL    8    1   \n",
       "...                                                   ...  ...  ...   \n",
       "282293      YAMENHSLREENRRLRLLEPVKRAQEMDAQTIAKLEKAFSEISGM   45    0   \n",
       "282294      LVPSPSLPRGCWQPPGSKSRPHRQGAQGHRAQVTQPSPKEPDRIK   45    0   \n",
       "282295     YRVYPEGTLELRRVTAEEAGLYTCVAQNLVGADTKTVSVVVGRALL   46    0   \n",
       "282296    LSLGQQLLRATADEDLQTAILLLAHGSREEVNETCGEGDGCTALHLA   47    0   \n",
       "282297  RDIGRVIKKSLVEATGVPGQHILVAVLPGLPTTAELFVLPYQDPAG...   51    0   \n",
       "\n",
       "        HLA_prob_pred  \n",
       "0            0.706319  \n",
       "1            0.971726  \n",
       "2            0.716983  \n",
       "3            0.948992  \n",
       "4            0.955846  \n",
       "...               ...  \n",
       "282293       0.940797  \n",
       "282294       0.828227  \n",
       "282295       0.981596  \n",
       "282296       0.650915  \n",
       "282297       0.985670  \n",
       "\n",
       "[282298 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = concat_neg_df(pos_test_df, model.protein_df)\n",
    "model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.8810354403137908\n",
      "Recall = 0.7192895450906489\n",
      "False Positive Rate = 0.09712431543971267\n"
     ]
    }
   ],
   "source": [
    "prob=0.7\n",
    "print(\"Precision =\", test_df[test_df.HLA_prob_pred>prob]['HLA'].mean())\n",
    "print(\"Recall =\", test_df[test_df.HLA_prob_pred>prob]['HLA'].sum()/len(test_df)*2)\n",
    "print(\"False Positive Rate =\", 1-(1-test_df[test_df.HLA_prob_pred<prob]['HLA']).sum()/len(test_df)*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all sequences with >0.7 predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\lib\\site-packages\\pydivsufsort\\divsufsort.py:76: UserWarning: converting str argument uses more memory\n",
      "  warnings.warn(\"converting str argument uses more memory\")\n",
      "d:\\workspace\\alphabase\\alphabase\\protein\\lcp_digest.py:9: UserWarning: converting str argument uses more memory\n",
      "  lcp_array = kasai(cat_prot, suffix_array)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [15:39<00:00, 13.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_pos</th>\n",
       "      <th>end_pos</th>\n",
       "      <th>nAA</th>\n",
       "      <th>HLA_prob_pred</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4709940</td>\n",
       "      <td>4709948</td>\n",
       "      <td>8</td>\n",
       "      <td>0.747321</td>\n",
       "      <td>ASVDYIRK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4709941</td>\n",
       "      <td>4709949</td>\n",
       "      <td>8</td>\n",
       "      <td>0.928773</td>\n",
       "      <td>SVDYIRKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4709943</td>\n",
       "      <td>4709951</td>\n",
       "      <td>8</td>\n",
       "      <td>0.797296</td>\n",
       "      <td>DYIRKLQR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4709951</td>\n",
       "      <td>4709959</td>\n",
       "      <td>8</td>\n",
       "      <td>0.824264</td>\n",
       "      <td>EQQRAKEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4709958</td>\n",
       "      <td>4709966</td>\n",
       "      <td>8</td>\n",
       "      <td>0.700991</td>\n",
       "      <td>LENRQKKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73207276</th>\n",
       "      <td>1232474</td>\n",
       "      <td>1232488</td>\n",
       "      <td>14</td>\n",
       "      <td>0.850721</td>\n",
       "      <td>TLLGAQPEDEAEYY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73207319</th>\n",
       "      <td>2563508</td>\n",
       "      <td>2563522</td>\n",
       "      <td>14</td>\n",
       "      <td>0.732092</td>\n",
       "      <td>VVGSRLDTPLGQTL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73207326</th>\n",
       "      <td>2563511</td>\n",
       "      <td>2563525</td>\n",
       "      <td>14</td>\n",
       "      <td>0.930226</td>\n",
       "      <td>SRLDTPLGQTLIRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73207335</th>\n",
       "      <td>4323141</td>\n",
       "      <td>4323155</td>\n",
       "      <td>14</td>\n",
       "      <td>0.790535</td>\n",
       "      <td>MGMMNNPNPYGSPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73207344</th>\n",
       "      <td>8588867</td>\n",
       "      <td>8588881</td>\n",
       "      <td>14</td>\n",
       "      <td>0.816129</td>\n",
       "      <td>DNLVAIFDVNRLGH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6039830 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start_pos  end_pos  nAA  HLA_prob_pred        sequence\n",
       "2           4709940  4709948    8       0.747321        ASVDYIRK\n",
       "3           4709941  4709949    8       0.928773        SVDYIRKL\n",
       "5           4709943  4709951    8       0.797296        DYIRKLQR\n",
       "13          4709951  4709959    8       0.824264        EQQRAKEL\n",
       "20          4709958  4709966    8       0.700991        LENRQKKL\n",
       "...             ...      ...  ...            ...             ...\n",
       "73207276    1232474  1232488   14       0.850721  TLLGAQPEDEAEYY\n",
       "73207319    2563508  2563522   14       0.732092  VVGSRLDTPLGQTL\n",
       "73207326    2563511  2563525   14       0.930226  SRLDTPLGQTLIRM\n",
       "73207335    4323141  4323155   14       0.790535  MGMMNNPNPYGSPY\n",
       "73207344    8588867  8588881   14       0.816129  DNLVAIFDVNRLGH\n",
       "\n",
       "[6039830 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hla_df = model.predict_from_proteins(prob_threshold=prob)\n",
    "hla_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hla_df.to_csv('Predicted_RA957_no_pretrain_HLA.tsv',index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a3b27e141e49c996c9b863f8707e97aabd49c4a7e8445b9b783b34e4a21a9b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
